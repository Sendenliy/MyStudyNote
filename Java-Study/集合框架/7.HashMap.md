## Map概述

1. `Map接口`：专门处理键值映射数据的存储，可以根据键实现对值的操作。  最常用的实现类是HashMap  

2. Map<K,V>接口常用方法

   <img src="https://img2023.cnblogs.com/blog/3406637/202403/3406637-20240322204605349-932618816.png" alt="image-20240322204603810" width="400" />

```java
//使用HashMap存储元素
public static void main(String[] args) {
    HashMap test = new HashMap();
    test.put(1, "覆盖前");
    test.put(1, "覆盖后");
    test.put(2, "two");
    test.put(3, "three");
    System.out.println(test);   //{1=覆盖后, 2=two, 3=three}
    //1.删除元素并返回元素
    System.out.println(test.remove(1)); //覆盖后
    //2.修改元素并返回修改前的元素
    System.out.println(test.replace(2, "2"));   //two
    //3.通过键查询值
    System.out.println(test.get(3));    //three
    //4.通过键查值如果键不存在，返回默认值
    System.out.println(test.getOrDefault(4, "这是默认值"));  //这是默认值
    System.out.println(test);   //{2=2, 3=three}
}
```

## HashMap数据结构

### HashMap概述

1. HashMap是基于哈希表的Map接口实现的，它存储的是内容是键值对<key,value>映射。
2. 此类不保证映射的顺序，假定哈希函数将元素适当的分布在各桶之间，可为基本操作(get和put)提供稳定的性能。
3. 在API中给出了相应的定义
   - 哈希表基于map接口的实现，这个实现提供了map所有的操作，并且提供了key和value，可以为null.
   - HashMap和HashTable大致上是一样的，除了hashmap是异步的，和允许key和value为null.
   - 这个类不确定map中元素的位置，特别要提的是，这个类也不确定元素的位置随着时间会不会保持不变。

------

- 假设哈希函数将元素合适的分到了每个桶(其实就是指的数组中位置上的链表)中，则这个实现为基本的操作(get、put)提供了稳定的性能.
- 迭代这个集合视图需要的时间跟hashMap实例(key-value映射的数量)的容量(在桶中)成正比，因此，如果迭代的性能很重要的话，就不要将初始容量设置的太高或者loadfactor设置的太低，【这里的桶，相当于在数组中每个位置上放一个桶装元素】

------

- HashMap的实例有两个参数影响性能，初始化容量(initialCapacity)和loadFactor加载因子，在哈希表中这个容量是桶的数量【也就是数组的长度】，一个初始化容量仅仅是在哈希表被创建时的容量。
- 在容量自动增长之前加载因子是衡量哈希表被允许达到多满的一种尺度。当entry的数量在哈希表中超过了加载因子乘以当前的容量，那么哈希表进行rehash操作(内部的数据结构会被重新建立)，所以哈希表有大约两倍的桶的数量  。

------

- 通常来讲，默认的加载因子(0.75)能够在时间和空间上提供一个好的平衡。加载因子更高的值会减少空间上的开支但是会增加查询花费的时间（体现在HashMap类中get、put方法上），当设置初始化容量时，应该考虑到map中会存放entry的数量和加载因子，以便最少次数的进行rehash操作，如果初始容量大于最大条目数除以加载因子，则不会发生 rehash 操作。
- 如果很多映射关系要存储在 HashMap 实例中，则相对于按需执行自动的 rehash 操作以增大表的容量来说，使用足够大的初始容量创建它将使得映射关系能更有效地存储。

### HashMap的数据结构和存储原理  -在JDK1.8以前

链表散列：数组和链表结合在一起使用

<img src="https://img2023.cnblogs.com/blog/3406637/202403/3406637-20240322211315253-1522051823.png" alt="image-20240322211314435" width="300" />

HashMap的数据结构就是用的`链表散列` 。使用该数据结构存取数据分两个部分

1. 第一步：HashMap内部有一个entry的内部类，其中有四个属性，我们要存储一个值，则需要一个key和一个value，存到map中就会先将key和value保存在这个Entry类创建的对象中。  

   ```java
   static class Entry<K,V> implements Map.Entry<K,V> {
       final K key; //就是我们说的map的key
       V value; //value值，这两个都不陌生
       Entry<K,V> next;//指向下一个entry对象
       int hash;//通过key算过来的你hashcode值。
   }
   ```

2. 第二步：构造好了entry对象，然后将该对象放入数组中，如何存放就是这hashMap的精华所在了.  

   大概的一个存放过程是：通过entry对象中的hash值来确定将该对象存放在数组中的哪个位置上，如果在这个位置上还有其他元素，则通过链表来存储这个元素。  

   <img src="https://img2023.cnblogs.com/blog/3406637/202403/3406637-20240322212609416-310648822.png" alt="image-20240322212608588" width="300" />

Hash存放元素的过程

- 通过key、value封装成一个entry对象
- 然后通过key的值来计算该entry的hash值
- 通过entry的hash值和数组的长度length来计算出entry放在数组中的哪个位置上面，每次存放都是将entry放在第一个位置。在这个过程中，就是通过hash值来确定将该对象存放在数组中的哪个位置上。

### HashMap的数据结构和存储原理  -在JDK1.8以后

HashMap的数据结构（`数组+链表+红黑树`），桶中的结构可能是链表，也可能是红黑树，红黑树的引入是为了提高效率 .

<img src="https://img2023.cnblogs.com/blog/3406637/202403/3406637-20240322213007440-4834379.png" alt="image-20240322213006241" width="300" />

### HashMap的属性

HashMap的实例有两个参数影响其性能。

- 初始容量：哈希表中桶的数量(初始化数组的大小)
- 加载因子：哈希表在其容量自动增加之前可以达到多满的一种尺度(数组上存放数据的疏密程度)

当哈希表中条目数超出了当前容量*加载因子(其实就是HashMap的实际容量)时，则对该哈希表进行rehash操作，将哈希表扩充至两倍的桶数

```java
//Java中默认初始容量为16，加载因子为0.75。
static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16
static final float DEFAULT_LOAD_FACTOR = 0.75f;
1 
```

1. loadFactor加载因子 

   ```java
   static final float DEFAULT_LOAD_FACTOR = 0.75f;
   ```

   - 装载因子用来衡量HashMap满的程度。loadFactor的默认值为0.75f。
   - 计算HashMap的实时装载因子的方法为：size/capacity，而不是占用桶的数量去除以capacity。
   - loadFactor加载因子是控制数组存放数据的疏密程度，loadFactor越趋近于1，那么数组中存放的数据(entry)也就越多，也就越密，也就是会让链表的长度增加，loadFactor越小，也就是趋近于0，那么数组中存放的数据也就越稀，也就是可能数组中每个位置上就放一个元素。
   - 那有人说，就把loadFactor变为1最好吗，存的数据很多。但是这样会有一个问题，就是我们在通过key拿到我们的value时，是先通过key的hashcode值，找到对应数组中的位置，如果该位置中有很多元素，则需要通过equals来依次比较链表中的元素，拿到我们的value值，这样花费的性能就很高。
   - 如果能让数组上的每个位置尽量只有一个元素最好，我们就能直接得到value值了，所以有人又会说，那把loadFactor变得很小不就好了，但是如果变得太小，在数组中的位置就会太稀，也就是分散的太开，浪费很多空间，这样也不好，所以在hashMap中loadFactor的初始值就是0.75，一般情况下不需要更改它。  

2. 桶

   根据前面画的HashMap存储的数据结构图，你这样想，数组中每一个位置上都放有一个桶，每个桶里就是装一个链表，链表中可以有很多个元素(entry)，这就是桶的意思。也就相当于把元素都放在桶中。  

3. capacity容量

   ```java
   static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16
   ```

   代表的数组的容量，也就是数组的长度，同时也是HashMap中桶的个数。默认值是16  

4. size的含义

   在该HashMap的实例中实际存储的元素的个数  

5. threshold的作用

   ```java
   int threshold;
   //threshold = capacity * loadFactor[DEFAULT_INITIAL_CAPACITY]
   ```

   - 当Size>=threshold的时候，那么就要考虑对数组的扩增了，也就是说，这个的意思就是衡量数组是否需要扩增的一个标准。
   - 注意这里说的是考虑，因为实际上要扩增数组，除了这个size>=threshold条件外，还需要另外一个条件。
   - 什么时候会扩增数组的大小？在put一个元素时先size>=threshold并且还要在对应数组位置上有元素，这才能扩增数组。

<img src="https://img2023.cnblogs.com/blog/3406637/202403/3406637-20240322214322511-2016359426.png" alt="image-20240322214321708" width="500" />

## HashMap的源码分析

### 继承结构

<img src="https://img2023.cnblogs.com/blog/3406637/202403/3406637-20240322215432337-139451406.png" alt="image-20240322215431617" style="zoom:50%;" />

```java
public class HashMap<K,V> extends AbstractMap<K,V>
    implements Map<K,V>, Cloneable, Serializable {}
```

- Map<K,V>：在AbstractMap抽象类中已经实现过的接口，这里又实现，实际上是多余的。但每个集合都有这样的错误，也没过大影响
- Cloneable：能够使用Clone()方法，在HashMap中，实现的是`浅层次拷贝`，即对拷贝对象的改变会影响被拷贝的对象。
- Serializable：能够使之序列化，即可以将HashMap对象保存至本地，之后可以恢复状态

### 类的属性

```java
public class HashMap<K,V> extends AbstractMap<K,V> implements Map<K,V>,
Cloneable, Serializable {
    // 序列号
    private static final long serialVersionUID = 362498820763181265L;
    // 默认的初始容量是16
    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4;
    // 最大容量
    static final int MAXIMUM_CAPACITY = 1 << 30;
    // 默认的填充因子
    static final float DEFAULT_LOAD_FACTOR = 0.75f;
    // 当桶(bucket)上的结点数大于这个值时会转成红黑树
    static final int TREEIFY_THRESHOLD = 8;
    // 当桶(bucket)上的结点数小于这个值时树转链表
    static final int UNTREEIFY_THRESHOLD = 6;
    // 桶中结构转化为红黑树对应的table的最小大小
    static final int MIN_TREEIFY_CAPACITY = 64;
    // 存储元素的数组，总是2的幂次倍
    transient Node<k,v>[] table;
    // 存放具体元素的集
    transient Set<map.entry<k,v>> entrySet;
    // 存放元素的个数，注意这个不等于数组的长度。
    transient int size;
    // 每次扩容和更改map结构的计数器
    transient int modCount;
    // 临界值 当实际大小(容量*填充因子)超过临界值时，会进行扩容
    int threshold;
    // 填充因子
    final float loadFactor;
}
```

### 构造方法

构造方法的作用就是记录一下16这个数给threshold（这个数值最终会当作第一次数组的长度）和初始化加载因子。

注意，hashMap中table数组一开始就已经是个没有长度的数组了。

构造方法中，并没有初始化数组的大小，数组在一开始就已经被创建了，构造方法只做两件事情，一个是初始化加载因子，另一个是用threshold记录下数组初始化的大小。注意是记录。

1. HashMap()

   ```java
   public HashMap() {
       this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted
   }
   ```

2. HashMap(int initialCapacity)

   ```java
   public HashMap(int initialCapacity) {
       this(initialCapacity, DEFAULT_LOAD_FACTOR);
   }
   ```

3. HashMap(int initialCapacity, float loadFactor)

   ```java
   public HashMap(int initialCapacity, float loadFactor) {
       //初识容量不能小于0，否则报错
       if (initialCapacity < 0)
           throw new IllegalArgumentException("Illegal initial capacity: " +initialCapacity);
       //初始容量不能大于最大值，否则为最大值
       if (initialCapacity > MAXIMUM_CAPACITY)
           initialCapacity = MAXIMUM_CAPACITY;
       //填充因子不能小于或等于0，不能为非数字
       if (loadFactor <= 0 || Float.isNaN(loadFactor))
           throw new IllegalArgumentException("Illegal load factor: " +loadFactor);
       //初始化填充因子
       this.loadFactor = loadFactor;
       //初始化threshold
       this.threshold = tableSizeFor(initialCapacity);
   }
   ```

4. HashMap(Map<? extends K, ? extends V> m)

   ```java
   public HashMap(Map<? extends K, ? extends V> m) {
       //初始化填充因子
       this.loadFactor = DEFAULT_LOAD_FACTOR;
       //将m中的所有元素添加到HashMap中
       putMapEntries(m, false);
   }
   ```

   putMapEntries(Map<? extends K, ? extends V> m, boolean evict)

   ```java
   final void putMapEntries(Map<? extends K, ? extends V> m, boolean evict) {
       int s = m.size();
       if (s > 0) {
   		// 判断table是否已经初始化
           if (table == null) { // pre-size
               // 未初始化，s为m的实际元素个数
               float ft = ((float)s / loadFactor) + 1.0F;
               int t = ((ft < (float)MAXIMUM_CAPACITY) ?(int)ft : MAXIMUM_CAPACITY);
               // 计算得到的t大于阈值，则初始化阈值
               if (t > threshold)
                   threshold = tableSizeFor(t);
           }
           // 已初始化，并且m元素个数大于阈值，进行扩容处理
           else if (s > threshold)
               resize();
           // 将m中的所有元素添加至HashMap中
           for (Map.Entry<? extends K, ? extends V> e : m.entrySet()) {
               K key = e.getKey();
               V value = e.getValue();
               putVal(hash(key), key, value, false, evict);
           }
       }
   }
   ```


### 常用方法

1. put(K key, V value)：插入元素

   ```java
   public V put(K key, V value) {
       return putVal(hash(key), key, value, false, true);
   }
   ```

2. putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict)

   ```java
   final V putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict) {
       Node<K,V>[] tab; Node<K,V> p; int n, i;
       //table未初始化或者长度为0，进行扩容
       if ((tab = table) == null || (n = tab.length) == 0)
           n = (tab = resize()).length;
       //(n-1) & hash确定元素存放在哪个桶中，桶为空，新生成节点放入桶中(此时节点是放在数组中的)
       if ((p = tab[i = (n - 1) & hash]) == null)
           tab[i] = newNode(hash, key, value, null);
       else {
           Node<K,V> e; K k;
           //比较桶中第一个元素(数组中的结点)的hash值相等，key相等
           if (p.hash == hash && ((k = p.key) == key || (key != null && key.equals(k))))
               //将第一个元素赋值给e，用e来记录
               e = p;
           //hash值不相等，即key不相等；为红黑树节点
           else if (p instanceof TreeNode)
               //放入树中
               e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
           //为链表结点
           else {
               //在链表最末插入结点
               for (int binCount = 0; ; ++binCount) {
                   //到达链表的尾部
                   if ((e = p.next) == null) {
                       //在尾部插入新结点
                       p.next = newNode(hash, key, value, null);
                       //结点数量达到阈值，转化为红黑树
                       if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                           treeifyBin(tab, hash);
                       //跳出循环
                       break;
                   }
                   //判断链表中结点的key值与插入元素的key值是否相等
                   if (e.hash == hash &&
                       ((k = e.key) == key || (key != null && key.equals(k))))
                       //相等就跳出循环
                       break;
                   //用于遍历桶中的链表，与前面的e=p.next组合，可以遍历链表
                   p = e;
               }
           }
           //表示在桶中找到key值、hash值与插入元素相等的结点
           if (e != null) { // existing mapping for key
               //记录e的value
               V oldValue = e.value;
               //onlyIfAbsent为false或者旧值为null
               if (!onlyIfAbsent || oldValue == null)
                   //用新值替换旧值
                   e.value = value;
               //访问后回调
               afterNodeAccess(e);
               //返回旧值
               return oldValue;
           }
       }
       //结构性修改
       ++modCount;
       //实际大小 > 阈值就扩容
       if (++size > threshold)
           resize();
       //插入后回调
       afterNodeInsertion(evict);
       return null;
   }
   ```

3. get(Object key)：取得元素

   ```java
   public V get(Object key) {
       Node<K,V> e;
       return (e = getNode(hash(key), key)) == null ? null : e.value;
   }
   ```

4. getNode(int hash, Object key)

   ```java
   final Node<K,V> getNode(int hash, Object key) {
       Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
       //table已经初始化，长度大于0，根据hash寻找table中的项也不为空
       if ((tab = table) != null && (n = tab.length) > 0 && (first = tab[(n - 1) & hash]) != null) {
           //桶中第一项相等
           if (first.hash == hash && // always check first node
               ((k = first.key) == key || (key != null && key.equals(k))))
               return first;
           //桶中不止一个结点
           if ((e = first.next) != null) {
               //为红黑树结点
               if (first instanceof TreeNode)
                   //在红黑树中查找
                   return ((TreeNode<K,V>)first).getTreeNode(hash, key);
               //否则，在链表中查找
               do {
                   if (e.hash == hash &&
                       ((k = e.key) == key || (key != null && key.equals(k))))
                       return e;
               } while ((e = e.next) != null);
           }
       }
       return null;
   }
   ```

5. resize():进行扩容，会伴随着一次重新hash分配，并且会遍历hash表中的所有元素，是非常耗时的。

   ```java
   final Node<K,V>[] resize() {
       //当前table保存
       Node<K,V>[] oldTab = table;
       //保存table大小
       int oldCap = (oldTab == null) ? 0 : oldTab.length;
       //保存当前阈值
       int oldThr = threshold;
       int newCap, newThr = 0;
       //之前table大小大于0
       if (oldCap > 0) {
           //之前table大于最大容量
           if (oldCap >= MAXIMUM_CAPACITY) {
               //阈值为最大整型
               threshold = Integer.MAX_VALUE;
               return oldTab;
           }
           //容量翻倍，使用左移，效率更高
           else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                    oldCap >= DEFAULT_INITIAL_CAPACITY)
               //阈值翻倍
               newThr = oldThr << 1; // double threshold
       }
       //之前阈值大于0
       else if (oldThr > 0) // initial capacity was placed in threshold
           newCap = oldThr;
       //oldCap=0 并且oldThr=0，使用缺省值（如使用HashMap()构造函数，之后再插入一个元素会调用resize函数，会进入这一步）
       else {               // zero initial threshold signifies using defaults
           newCap = DEFAULT_INITIAL_CAPACITY;
           newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
       }
       //新阈值=0
       if (newThr == 0) {
           float ft = (float)newCap * loadFactor;
           newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                     (int)ft : Integer.MAX_VALUE);
       }
       threshold = newThr;
       @SuppressWarnings({"rawtypes","unchecked"})
       //初始化table
       Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
       table = newTab;
       //之前的table已经初始化过
       if (oldTab != null) {
           //复制元素，重新进行hash
           for (int j = 0; j < oldCap; ++j) {
               Node<K,V> e;
               if ((e = oldTab[j]) != null) {
                   oldTab[j] = null;
                   if (e.next == null)
                       newTab[e.hash & (newCap - 1)] = e;
                   else if (e instanceof TreeNode)
                       ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                   else { // preserve order
                       Node<K,V> loHead = null, loTail = null;
                       Node<K,V> hiHead = null, hiTail = null;
                       Node<K,V> next;
                       //将同一桶中的元素根据(e.hash & oldCap)是否为0进行分割，分成两个不同的链表，完成rehash
                       do {
                           next = e.next;
                           if ((e.hash & oldCap) == 0) {
                               if (loTail == null)
                                   loHead = e;
                               else
                                   loTail.next = e;
                               loTail = e;
                           }
                           else {
                               if (hiTail == null)
                                   hiHead = e;
                               else
                                   hiTail.next = e;
                               hiTail = e;
                           }
                       } while ((e = next) != null);
                       if (loTail != null) {
                           loTail.next = null;
                           newTab[j] = loHead;
                       }
                       if (hiTail != null) {
                           hiTail.next = null;
                           newTab[j + oldCap] = hiHead;
                       }
                   }
               }
           }
       }
       return newTab;
   }
   ```

   resize前后的元素布局：

   <img src="https://img2023.cnblogs.com/blog/3406637/202403/3406637-20240323142948377-746840840.png" alt="image-20240323142948153" width="300" />

## 总结

### 关于数组扩容

1. 从putVal源代码中我们可以知道，当插入一个元素的时候size就加1，若`size大于threshold`的时候，就会进行`扩容`。
2. 假设我们的capacity大小为32，loadFator为0.75,则threshold为24 = 32 * 0.75，此时，插入了25个元素，并且插入的这25个元素都在同一个桶中，桶中的数据结构为红黑树，则还有31个桶是空的，也会进行扩容处理，其实，此时，还有31个桶是空的，好像似乎不需要进行扩容处理，但是是需要扩容处理的，因为此时我们的capacity大小可能不适当。
3. 我们前面知道，扩容处理会遍历所有的元素，时间复杂度很高；前面我们还知道，经过一次扩容处理后，元素会更加均匀的分布在各个桶中，会提升访问效率。所以，说尽量避免进行扩容处理，也就意味着，`遍历元素所带来的坏处大于元素在桶中均匀分布所带来的好处`。

### 总结

1. 要知道hashMap在JDK1.8以前是一个`链表散列`这样一个数据结构，而在JDK1.8以后是一个`数组加链表加红黑树`的数据结构。
2. 通过源码的学习，hashMap是一个能快速通过key获取到value值得一个集合，原因是内部使用的是hash查找值得方法。
